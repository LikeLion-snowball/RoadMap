# import requests
from bs4 import BeautifulSoup
from selenium import webdriver
import time
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import pandas as pd


def iframe():
    try:
        driver.switch_to.frame("cafe_main")
    except:
        pass

# chrome_options = Options()
# chrome_options.add_argument("--headless")

# driver = webdriver.Chrome('/Users/yujin/sookmyung/chromedriver', options=chrome_options)
driver = webdriver.Chrome('/Users/yujin/sookmyung/chromedriver')


# driver.get('https://m.cafe.naver.com/ca-fe/web/cafes/15754634/menus/1481')
# driver.switch_to.frame("cafe_main")
driver.get('https://cafe.naver.com/specup')
driver.implicitly_wait(3)

driver.find_element_by_xpath('//*[@id="menuLink1481"]').click()
time.sleep(2)

iframe()

for i in range(1, 3):
    html = BeautifulSoup(driver.page_source, 'html.parser')
    titles = html.select('#main-area > div:nth-child(6) > table > tbody > tr')

    list3 = []

    for title in titles:
        list = title.select_one(' td.td_article > div.board-list > div > a').text
        list2 = ''.join(list.split())
        list3.append(list2)

    # list4_sr = pd.Series(list3)
    # print(list4_sr)
    # print(list3)

    for a in range(1, 3):
        driver.find_element_by_xpath(f'//*[@id="main-area"]/div[4]/table/tbody/tr[{a}]/td[1]/div[2]/div/a').click()
        time.sleep(2)

        html = BeautifulSoup(driver.page_source , 'html.parser')
        titles = html.select("h3.title_text")
        content_tags = html.select('div.se-section.se-section-text.se-l-default')
        # ë³¸ë¬¸ ë‚´ìš©ì„ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ ë¶™ì´ê¸°
        exclude1 = 'â–¼ì±„ìš©ê³µê³ â–¼'
        exclude2 = 'ì±„ìš©ê³µê³  ë°”ë¡œ ë³´ê¸°(í´ë¦­) â€‹â€‹â–¼ìŠ¤í™ì—…ì—ì„œ ì·¨ì¤€ ì•Œì°¨ê²Œ í•˜ëŠ” ë°©ë²•â–¼ â€‹ğŸ‘‰ê¸°ì—…ë³„ ì±„ìš©ì†Œì‹/ì •ë³´ ê°€ì¥ ë¹ ë¥´ê²Œ ë°›ê¸° https://open.kakao.com/o/gg8n52gâ€‹â€‹ğŸ‘‰ìì†Œì„œ ì²¨ì‚­ ë¬´ë£Œë¡œ! ë°›ê¸° https://vo.la/EPyxâ€‹â€‹ğŸìì†Œì„œ&ë©´ì ‘ ëŒ€ë¹„ í•„ìˆ˜ ìë£Œ! ê¸°ì—… ìµœì‹ ì´ìŠˆ+ë©´ì ‘ê¸°ì¶œ+ë‹µì•ˆ ìƒì„¸ ì •ë¦¬! ğŸ‘‡ê¸°ì—…ë¶„ì„ ìë£Œ ë°”ë¡œ ë°›ê¸° https://bit.ly/3wp6egA'
        content = ' '.join([tags.get_text().replace("â–¶","\n").replace(exclude1,"").replace(exclude2,"") for tags in content_tags])
        print(content)
        print()
        print()

        driver.back()
        time.sleep(2)
        iframe()

driver.close()